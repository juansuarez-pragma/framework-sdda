# MÃ©tricas del Framework SDDA

Indicadores clave para medir la efectividad del desarrollo con SDDA.

---

## CategorÃ­as de MÃ©tricas

1. [MÃ©tricas de Calidad de CÃ³digo](#mÃ©tricas-de-calidad-de-cÃ³digo)
2. [MÃ©tricas de Testing](#mÃ©tricas-de-testing)
3. [MÃ©tricas de Productividad](#mÃ©tricas-de-productividad)
4. [MÃ©tricas de Proceso](#mÃ©tricas-de-proceso)
5. [MÃ©tricas de IA](#mÃ©tricas-de-ia)

---

## MÃ©tricas de Calidad de CÃ³digo

### 1. Code Coverage (Cobertura de CÃ³digo)

**DefiniciÃ³n**: Porcentaje de lÃ­neas de cÃ³digo ejecutadas por tests.

| Nivel | Cobertura | Estado |
|-------|-----------|--------|
| CrÃ­tico | < 60% | ğŸ”´ Inaceptable |
| Bajo | 60-79% | ğŸŸ¡ Mejorar |
| **Target** | **â‰¥ 80%** | ğŸŸ¢ **Aceptable** |
| Excelente | â‰¥ 90% | ğŸŸ¢ Ã“ptimo |

**CÃ³mo medir**:
```bash
flutter test --coverage
lcov --summary coverage/lcov.info

# Output esperado:
# lines......: 85.3% (1234 of 1447 lines)
```

**Por capa**:
| Capa | Target MÃ­nimo |
|------|---------------|
| Domain (UseCases) | 95% |
| Data (Repositories) | 85% |
| Presentation (BLoC) | 90% |
| Presentation (Widgets) | 70% |

### 2. Mutation Score (PuntuaciÃ³n de MutaciÃ³n)

**DefiniciÃ³n**: Porcentaje de mutantes (cÃ³digo modificado) detectados por tests.

| Nivel | Score | InterpretaciÃ³n |
|-------|-------|----------------|
| Bajo | < 50% | Tests dÃ©biles |
| Medio | 50-69% | Tests moderados |
| **Target** | **â‰¥ 70%** | **Tests robustos** |
| Alto | â‰¥ 85% | Tests muy robustos |

**CÃ³mo medir**:
```bash
# Usando mutation testing (ejemplo con stryker)
dart run stryker:stryker

# Output:
# Mutation Score: 75.2%
# Killed: 188, Survived: 62, Timeout: 5
```

### 3. Complejidad CiclomÃ¡tica

**DefiniciÃ³n**: NÃºmero de caminos linealmente independientes en el cÃ³digo.

| Complejidad | Riesgo | AcciÃ³n |
|-------------|--------|--------|
| 1-10 | Bajo | âœ… Aceptable |
| 11-20 | Medio | âš ï¸ Revisar |
| 21-50 | Alto | ğŸ”´ Refactorizar |
| > 50 | Muy Alto | ğŸ”´ Dividir |

**Target SDDA**: MÃ¡ximo 10 por mÃ©todo.

**CÃ³mo medir**:
```bash
dart run dart_code_metrics:metrics analyze lib/

# O con flutter analyze
flutter analyze --no-fatal-infos
```

### 4. Violaciones de Arquitectura

**DefiniciÃ³n**: Imports que violan las reglas de dependencia de Clean Architecture.

| ViolaciÃ³n | Severidad |
|-----------|-----------|
| Domain importa Data | ğŸ”´ CrÃ­tica |
| Domain importa Presentation | ğŸ”´ CrÃ­tica |
| Presentation importa Data | ğŸŸ¡ Alta |
| Data importa Presentation | ğŸ”´ CrÃ­tica |

**Target**: 0 violaciones.

**CÃ³mo medir**:
```bash
sdda validate --all --architecture

# Output:
# Architecture violations: 0
```

---

## MÃ©tricas de Testing

### 5. Test Pass Rate

**DefiniciÃ³n**: Porcentaje de tests que pasan.

| Rate | Estado |
|------|--------|
| < 100% | ğŸ”´ No desplegar |
| **100%** | ğŸŸ¢ **Requerido** |

**CÃ³mo medir**:
```bash
flutter test

# Output:
# 00:05 +45: All tests passed!
```

### 6. Test Execution Time

**DefiniciÃ³n**: Tiempo total para ejecutar todos los tests.

| Tipo | Target |
|------|--------|
| Unit Tests (1000) | < 30 segundos |
| Widget Tests (100) | < 60 segundos |
| Integration Tests (20) | < 5 minutos |
| E2E Tests (10) | < 10 minutos |

**CÃ³mo medir**:
```bash
time flutter test

# Output:
# real    0m28.456s
```

### 7. Test Distribution

**DefiniciÃ³n**: ProporciÃ³n de tests por tipo (PirÃ¡mide de Testing).

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   E2E     â”‚  5-10%
                    â”‚   Tests   â”‚
                   â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Integration   â”‚  15-20%
                  â”‚    Tests      â”‚
                 â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Widget Tests    â”‚  20-25%
               â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     Unit Tests        â”‚  50-60%
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Target Distribution**:
| Tipo | Porcentaje |
|------|------------|
| Unit | 50-60% |
| Widget | 20-25% |
| Integration | 15-20% |
| E2E | 5-10% |

### 8. Flaky Test Rate

**DefiniciÃ³n**: Porcentaje de tests que fallan intermitentemente.

| Rate | Estado |
|------|--------|
| > 5% | ğŸ”´ CrÃ­tico |
| 1-5% | ğŸŸ¡ AtenciÃ³n |
| **< 1%** | ğŸŸ¢ **Target** |
| 0% | ğŸŸ¢ Ã“ptimo |

---

## MÃ©tricas de Productividad

### 9. Feature Delivery Time

**DefiniciÃ³n**: Tiempo desde especificaciÃ³n hasta cÃ³digo validado.

| Complejidad | Target |
|-------------|--------|
| Simple (1-2 UseCases) | 1-2 dÃ­as |
| Media (3-5 UseCases) | 3-5 dÃ­as |
| Compleja (6+ UseCases) | 1-2 semanas |

**Desglose tÃ­pico**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Feature Delivery Time                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚   SPECIFY    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  20%           â”‚
â”‚   CONTRACT   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  30%           â”‚
â”‚   GENERATE   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  20%           â”‚
â”‚   VALIDATE   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  30%           â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10. Code Generation Ratio

**DefiniciÃ³n**: Porcentaje de cÃ³digo generado automÃ¡ticamente vs manual.

| Ratio | Nivel de AutomatizaciÃ³n |
|-------|------------------------|
| < 50% | Bajo |
| 50-70% | Medio |
| **70-85%** | **Target SDDA** |
| > 85% | Alto |

**Por componente**:
| Componente | % Generado Esperado |
|------------|---------------------|
| Entities | 90% |
| Models | 95% |
| Repository Interface | 95% |
| Repository Impl | 80% |
| UseCases | 85% |
| BLoC | 80% |
| Widgets | 50% |

### 11. Rework Rate

**DefiniciÃ³n**: Porcentaje de cÃ³digo que necesita ser reescrito despuÃ©s de generaciÃ³n.

| Rate | Estado |
|------|--------|
| > 30% | ğŸ”´ EspecificaciÃ³n pobre |
| 15-30% | ğŸŸ¡ Mejorar contexto |
| **5-15%** | ğŸŸ¢ **Normal** |
| < 5% | ğŸŸ¢ Excelente |

---

## MÃ©tricas de Proceso

### 12. Specification Completeness

**DefiniciÃ³n**: QuÃ© tan completas estÃ¡n las especificaciones antes de generar.

**Checklist** (cada Ã­tem vale 10%):
- [ ] Entidades definidas con todos los campos
- [ ] UseCases con params y return types
- [ ] Validaciones especificadas
- [ ] Failures documentados
- [ ] API endpoints definidos
- [ ] Eventos del BLoC listados
- [ ] Estados del BLoC listados
- [ ] Requisitos de negocio claros
- [ ] Criterios de aceptaciÃ³n
- [ ] Dependencias identificadas

**Target**: â‰¥ 80% antes de GENERATE.

### 13. Contract Coverage

**DefiniciÃ³n**: Porcentaje de especificaciÃ³n cubierta por tests-contrato.

| Coverage | Estado |
|----------|--------|
| < 70% | ğŸ”´ Insuficiente |
| 70-89% | ğŸŸ¡ Aceptable |
| **â‰¥ 90%** | ğŸŸ¢ **Target** |

**FÃ³rmula**:
```
Contract Coverage = (Tests escritos / Comportamientos especificados) Ã— 100
```

### 14. First-Pass Success Rate

**DefiniciÃ³n**: Porcentaje de generaciones que pasan validaciÃ³n en el primer intento.

| Rate | Estado |
|------|--------|
| < 50% | ğŸ”´ Contexto insuficiente |
| 50-70% | ğŸŸ¡ Mejorar patrones |
| **70-85%** | ğŸŸ¢ **Normal** |
| > 85% | ğŸŸ¢ Excelente |

---

## MÃ©tricas de IA

### 15. Hallucination Rate

**DefiniciÃ³n**: Frecuencia con que la IA genera cÃ³digo que referencia APIs/mÃ©todos inexistentes.

| Rate | Estado |
|------|--------|
| > 20% | ğŸ”´ Contexto muy pobre |
| 10-20% | ğŸŸ¡ Mejorar documentaciÃ³n |
| **< 10%** | ğŸŸ¢ **Target** |
| < 5% | ğŸŸ¢ Excelente |

**CÃ³mo detectar**:
```bash
# Compilar cÃ³digo generado
flutter analyze lib/features/[nuevo]/

# Errores de "undefined" indican alucinaciones
# Analyzing...
# error: Undefined name 'NonExistentClass'
```

### 16. Pattern Adherence

**DefiniciÃ³n**: QuÃ© tan bien el cÃ³digo generado sigue los patrones de ejemplo.

**Criterios** (escala 1-5):
| Criterio | 1 | 5 |
|----------|---|---|
| Estructura de archivos | Diferente | IdÃ©ntica |
| Nombrado de clases | Inconsistente | Consistente |
| Manejo de errores | Diferente | Igual al patrÃ³n |
| DocumentaciÃ³n | Ausente | Completa |
| Imports | Desordenados | SegÃºn convenciÃ³n |

**Target**: Promedio â‰¥ 4.0

### 17. Prompt Efficiency

**DefiniciÃ³n**: NÃºmero de iteraciones de prompt necesarias para obtener cÃ³digo correcto.

| Iteraciones | Eficiencia |
|-------------|------------|
| 1 | ğŸŸ¢ Excelente |
| **2-3** | ğŸŸ¢ **Normal** |
| 4-5 | ğŸŸ¡ Revisar prompt |
| > 5 | ğŸ”´ RediseÃ±ar prompt |

---

## Dashboard de MÃ©tricas

### Template de Reporte Semanal

```markdown
# Reporte SDDA - Semana [X]

## Resumen Ejecutivo
| MÃ©trica | Target | Actual | Estado |
|---------|--------|--------|--------|
| Coverage | â‰¥80% | 85% | ğŸŸ¢ |
| Test Pass | 100% | 100% | ğŸŸ¢ |
| Mutation Score | â‰¥70% | 72% | ğŸŸ¢ |
| First-Pass Success | â‰¥70% | 75% | ğŸŸ¢ |
| Hallucination Rate | <10% | 8% | ğŸŸ¢ |

## Features Completados
| Feature | Tiempo | Coverage | Tests |
|---------|--------|----------|-------|
| auth | 3 dÃ­as | 92% | 45 |
| products | 4 dÃ­as | 88% | 62 |

## Ãreas de Mejora
1. [Ãrea 1]
2. [Ãrea 2]

## Acciones
1. [AcciÃ³n 1]
2. [AcciÃ³n 2]
```

---

## Herramientas de MediciÃ³n

| MÃ©trica | Herramienta |
|---------|-------------|
| Coverage | `flutter test --coverage` + lcov |
| Mutation | stryker-mutator |
| Complejidad | dart_code_metrics |
| Arquitectura | `sdda validate` |
| Tiempo | Git commits, JIRA |

---

## Siguiente Paso

Ver la [GuÃ­a de EvaluaciÃ³n](./EVALUACION.md) para interpretar estas mÃ©tricas.
