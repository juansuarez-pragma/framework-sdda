# MÃ©tricas del Framework SDDA

Indicadores clave para medir la efectividad del desarrollo con SDDA.

---

## Principio Fundamental de Cobertura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                             â”‚
â”‚   SDDA REQUIERE 100% DE COBERTURA EN CÃ“DIGO TESTEABLE                      â”‚
â”‚                                                                             â”‚
â”‚   "Si el cÃ³digo tiene lÃ³gica, DEBE tener test"                             â”‚
â”‚   "Si no tiene test, NO se genera"                                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

El objetivo de SDDA es generar cÃ³digo **100% correcto**. Esto solo es verificable con **100% de cobertura** en cÃ³digo que contiene lÃ³gica.

---

## CategorÃ­as de MÃ©tricas

1. [MÃ©tricas de Calidad de CÃ³digo](#mÃ©tricas-de-calidad-de-cÃ³digo)
2. [MÃ©tricas de Testing](#mÃ©tricas-de-testing)
3. [MÃ©tricas de Productividad](#mÃ©tricas-de-productividad)
4. [MÃ©tricas de Proceso](#mÃ©tricas-de-proceso)
5. [MÃ©tricas de IA](#mÃ©tricas-de-ia)

---

## MÃ©tricas de Calidad de CÃ³digo

### 1. Code Coverage (Cobertura de CÃ³digo)

**DefiniciÃ³n**: Porcentaje de lÃ­neas de cÃ³digo ejecutadas por tests.

| Nivel | Cobertura | Estado |
|-------|-----------|--------|
| CrÃ­tico | < 80% | ğŸ”´ Inaceptable |
| Insuficiente | 80-94% | ğŸŸ¡ Mejorar |
| Aceptable | 95-99% | ğŸŸ¢ Casi completo |
| **Target SDDA** | **100%*** | ğŸŸ¢ **Requerido** |

*\*100% del cÃ³digo testeable (ver [Excepciones Justificadas](#excepciones-justificadas-al-100))*

**CÃ³mo medir**:
```bash
flutter test --coverage
lcov --summary coverage/lcov.info

# Output esperado:
# lines......: 100.0% (1447 of 1447 lines)
```

**Por capa (OBLIGATORIO)**:
| Capa | Target | JustificaciÃ³n |
|------|--------|---------------|
| Domain (Entities) | 100% | LÃ³gica de negocio pura |
| Domain (UseCases) | 100% | Reglas de negocio crÃ­ticas |
| Data (Repositories) | 100% | CoordinaciÃ³n de datos |
| Data (DataSources) | 100% | ComunicaciÃ³n externa |
| Data (Models) | 100%* | SerializaciÃ³n JSON |
| Presentation (BLoC) | 100% | GestiÃ³n de estado |
| Presentation (Widgets) | 100%** | Comportamiento UI |

*\*Excluir cÃ³digo auto-generado (.g.dart)*
*\*\*Excluir widgets puramente declarativos sin lÃ³gica*

---

### Excepciones Justificadas al 100%

Basado en investigaciÃ³n de [Very Good Ventures](https://www.verygood.ventures/blog/road-to-100-test-coverage) y mejores prÃ¡cticas de la industria, las **Ãºnicas excepciones vÃ¡lidas** son:

#### âœ… CÃ³digo que PUEDE excluirse del coverage

| Tipo | RazÃ³n | Ejemplo |
|------|-------|---------|
| **CÃ³digo auto-generado** | No es cÃ³digo que escribimos | `*.g.dart`, `*.freezed.dart` |
| **Localizaciones generadas** | Generado por herramientas | `l10n/*.dart` |
| **Assets generados** | Referencias automÃ¡ticas | `assets.gen.dart` |
| **Constructores const** | Ejecutados antes de tests | `const MyWidget()` |
| **main() de la app** | Punto de entrada | `lib/main.dart` |
| **ConfiguraciÃ³n de DI** | Setup de inyecciÃ³n | `injection.dart` |

#### âŒ CÃ³digo que NUNCA puede excluirse

| Tipo | RazÃ³n |
|------|-------|
| **UseCases** | Contienen lÃ³gica de negocio |
| **BLoCs/Cubits** | Contienen lÃ³gica de estado |
| **Repository Implementations** | Contienen lÃ³gica de coordinaciÃ³n |
| **Validaciones** | Contienen reglas crÃ­ticas |
| **Mappers/Converters** | Contienen transformaciones |
| **Error Handlers** | Contienen flujo de errores |

#### ConfiguraciÃ³n de Exclusiones

```yaml
# lcov.yaml o en CI/CD
exclude:
  - "**/*.g.dart"           # json_serializable
  - "**/*.freezed.dart"     # freezed
  - "**/*.gen.dart"         # assets
  - "**/l10n/**"            # localizaciones
  - "**/injection.dart"     # DI setup
  - "**/main.dart"          # entry point
  - "**/firebase_options.dart"  # config generado
```

```bash
# Comando para filtrar coverage
lcov --remove coverage/lcov.info \
  '**/*.g.dart' \
  '**/*.freezed.dart' \
  '**/l10n/*' \
  -o coverage/lcov_filtered.info
```

---

### 2. Mutation Score (PuntuaciÃ³n de MutaciÃ³n)

**DefiniciÃ³n**: Porcentaje de mutantes (cÃ³digo modificado) detectados por tests.

| Nivel | Score | InterpretaciÃ³n |
|-------|-------|----------------|
| CrÃ­tico | < 70% | Tests no detectan cambios |
| Insuficiente | 70-84% | Tests parcialmente efectivos |
| Bueno | 85-94% | Tests robustos |
| **Target SDDA** | **â‰¥ 95%** | **Tests exhaustivos** |

> **Nota**: 100% de coverage NO garantiza tests de calidad. El mutation score verifica que los tests realmente detectan errores.

**CÃ³mo medir**:
```bash
dart run stryker:stryker

# Output esperado:
# Mutation Score: 96.2%
# Killed: 245, Survived: 10, Timeout: 3
```

---

### 3. Complejidad CiclomÃ¡tica

**DefiniciÃ³n**: NÃºmero de caminos linealmente independientes en el cÃ³digo.

| Complejidad | Riesgo | AcciÃ³n |
|-------------|--------|--------|
| 1-10 | Bajo | âœ… Aceptable |
| 11-20 | Medio | âš ï¸ Revisar |
| 21-50 | Alto | ğŸ”´ Refactorizar |
| > 50 | Muy Alto | ğŸ”´ Dividir |

**Target SDDA**: MÃ¡ximo 10 por mÃ©todo.

> **JustificaciÃ³n**: CÃ³digo con complejidad > 10 es difÃ­cil de testear al 100%. Si la complejidad es alta, el cÃ³digo debe refactorizarse ANTES de generar tests.

---

### 4. Violaciones de Arquitectura

**DefiniciÃ³n**: Imports que violan las reglas de dependencia de Clean Architecture.

| ViolaciÃ³n | Severidad |
|-----------|-----------|
| Domain importa Data | ğŸ”´ CrÃ­tica |
| Domain importa Presentation | ğŸ”´ CrÃ­tica |
| Presentation importa Data | ğŸ”´ CrÃ­tica |
| Data importa Presentation | ğŸ”´ CrÃ­tica |

**Target**: 0 violaciones (no negociable).

---

## MÃ©tricas de Testing

### 5. Test Pass Rate

**DefiniciÃ³n**: Porcentaje de tests que pasan.

| Rate | Estado |
|------|--------|
| < 100% | ğŸ”´ **BLOQUEA DEPLOY** |
| **100%** | ğŸŸ¢ **Ãšnico valor aceptable** |

> En SDDA, un test que falla significa que el cÃ³digo generado es incorrecto. **No se despliega cÃ³digo con tests fallando.**

---

### 6. Contract Coverage (Cobertura de Contrato)

**DefiniciÃ³n**: Porcentaje de comportamientos especificados cubiertos por tests-contrato.

| Coverage | Estado |
|----------|--------|
| < 90% | ğŸ”´ EspecificaciÃ³n incompleta |
| 90-99% | ğŸŸ¡ Casi completo |
| **100%** | ğŸŸ¢ **Requerido** |

**FÃ³rmula**:
```
Contract Coverage = (Tests escritos / Comportamientos en spec) Ã— 100
```

**Cada spec DEBE tener tests para**:
- âœ… Todos los casos de Ã©xito
- âœ… Todas las validaciones
- âœ… Todos los failures definidos
- âœ… Todos los edge cases identificados

---

### 7. Test Distribution (PirÃ¡mide)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   E2E     â”‚  5%
                    â”‚   Tests   â”‚
                   â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Integration   â”‚  15%
                  â”‚    Tests      â”‚
                 â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Widget Tests    â”‚  25%
               â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     Unit Tests        â”‚  55%
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Tipo | Porcentaje | Coverage interno |
|------|------------|------------------|
| Unit | 55% | 100% |
| Widget | 25% | 100% |
| Integration | 15% | 100% |
| E2E | 5% | Flujos crÃ­ticos |

---

### 8. Flaky Test Rate

**DefiniciÃ³n**: Porcentaje de tests que fallan intermitentemente.

| Rate | Estado |
|------|--------|
| > 1% | ğŸ”´ Inaceptable |
| 0.1-1% | ğŸŸ¡ Investigar |
| **0%** | ğŸŸ¢ **Target** |

> Tests flaky indican problemas de diseÃ±o. En SDDA, un test flaky es un **bug** que debe corregirse inmediatamente.

---

## MÃ©tricas de Productividad

### 9. Feature Delivery Time

| Complejidad | Target |
|-------------|--------|
| Simple (1-2 UseCases) | 1-2 dÃ­as |
| Media (3-5 UseCases) | 3-5 dÃ­as |
| Compleja (6+ UseCases) | 1-2 semanas |

**Desglose tÃ­pico SDDA**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Feature Delivery Time                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚   SPECIFY    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  20%           â”‚
â”‚   CONTRACT   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  30%           â”‚
â”‚   GENERATE   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  15%           â”‚
â”‚   VALIDATE   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  35%           â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **Nota**: VALIDATE incluye asegurar 100% coverage. El tiempo adicional se compensa con **0 bugs en producciÃ³n**.

---

### 10. Code Generation Ratio

| Ratio | Nivel |
|-------|-------|
| < 70% | Bajo |
| 70-85% | Medio |
| **85-95%** | **Target SDDA** |
| > 95% | Ã“ptimo |

**Por componente**:
| Componente | % Generado | % Tests Generados |
|------------|------------|-------------------|
| Entities | 95% | 100% |
| Models | 98% | 100% |
| Repository Interface | 98% | N/A |
| Repository Impl | 90% | 100% |
| UseCases | 95% | 100% |
| BLoC | 90% | 100% |
| Widgets | 60% | 100% |

---

### 11. Rework Rate

| Rate | Estado |
|------|--------|
| > 15% | ğŸ”´ EspecificaciÃ³n deficiente |
| 5-15% | ğŸŸ¡ Mejorar contexto |
| **< 5%** | ğŸŸ¢ **Target** |
| 0% | ğŸŸ¢ Ã“ptimo |

---

## MÃ©tricas de Proceso

### 12. Specification Completeness

**Checklist OBLIGATORIO** (100% requerido):

- [ ] Entidades definidas con todos los campos
- [ ] Tipos de datos especificados
- [ ] Validaciones documentadas
- [ ] Failures listados exhaustivamente
- [ ] UseCases con params y return types
- [ ] API endpoints definidos (si aplica)
- [ ] Eventos del BLoC listados
- [ ] Estados del BLoC con propiedades
- [ ] Criterios de aceptaciÃ³n claros
- [ ] Edge cases identificados

**Target**: 100% antes de escribir tests.

---

### 13. First-Pass Success Rate

| Rate | Estado |
|------|--------|
| < 70% | ğŸ”´ Contexto insuficiente |
| 70-85% | ğŸŸ¡ Mejorar patrones |
| 85-95% | ğŸŸ¢ Bueno |
| **> 95%** | ğŸŸ¢ **Target** |

---

## MÃ©tricas de IA

### 14. Hallucination Rate

| Rate | Estado |
|------|--------|
| > 10% | ğŸ”´ Contexto muy pobre |
| 5-10% | ğŸŸ¡ Mejorar documentaciÃ³n |
| 1-5% | ğŸŸ¢ Aceptable |
| **< 1%** | ğŸŸ¢ **Target** |

---

### 15. Pattern Adherence

**Criterios** (escala 1-5):
| Criterio | 1 | 5 |
|----------|---|---|
| Estructura de archivos | Diferente | IdÃ©ntica |
| Nombrado de clases | Inconsistente | Consistente |
| Manejo de errores | Diferente | Igual al patrÃ³n |
| DocumentaciÃ³n | Ausente | Completa |
| Imports | Desordenados | SegÃºn convenciÃ³n |

**Target**: 5.0 (perfecto)

---

### 16. Prompt Efficiency

| Iteraciones | Eficiencia |
|-------------|------------|
| **1** | ğŸŸ¢ **Target** |
| 2 | ğŸŸ¢ Aceptable |
| 3 | ğŸŸ¡ Revisar prompt |
| > 3 | ğŸ”´ RediseÃ±ar |

---

## Dashboard de MÃ©tricas

### Template de Reporte Semanal

```markdown
# Reporte SDDA - Semana [X]

## Resumen Ejecutivo
| MÃ©trica | Target | Actual | Estado |
|---------|--------|--------|--------|
| Coverage (testeable) | 100% | 100% | ğŸŸ¢ |
| Test Pass | 100% | 100% | ğŸŸ¢ |
| Mutation Score | â‰¥95% | 96% | ğŸŸ¢ |
| First-Pass Success | â‰¥95% | 97% | ğŸŸ¢ |
| Hallucination Rate | <1% | 0.5% | ğŸŸ¢ |
| Rework Rate | <5% | 3% | ğŸŸ¢ |

## Features Completados
| Feature | Tiempo | Coverage | Mutation | Tests |
|---------|--------|----------|----------|-------|
| auth | 3 dÃ­as | 100% | 96% | 45 |
| products | 4 dÃ­as | 100% | 95% | 62 |

## CÃ³digo Excluido del Coverage
| Archivo | RazÃ³n | Aprobado |
|---------|-------|----------|
| *.g.dart | Auto-generado | âœ… |
| l10n/* | Localizaciones | âœ… |
```

---

## Herramientas de MediciÃ³n

| MÃ©trica | Herramienta |
|---------|-------------|
| Coverage | `flutter test --coverage` + lcov |
| Mutation | stryker-mutator |
| Complejidad | dart_code_metrics |
| Arquitectura | `sdda validate` |

---

## Resumen de Targets SDDA

| MÃ©trica | Target | Negociable |
|---------|--------|------------|
| Code Coverage (testeable) | 100% | âŒ No |
| Test Pass Rate | 100% | âŒ No |
| Mutation Score | â‰¥95% | âš ï¸ MÃ­nimo 90% |
| Architecture Violations | 0 | âŒ No |
| Contract Coverage | 100% | âŒ No |
| Flaky Tests | 0% | âŒ No |
| First-Pass Success | â‰¥95% | âš ï¸ MÃ­nimo 85% |
| Hallucination Rate | <1% | âš ï¸ MÃ¡ximo 5% |
| Rework Rate | <5% | âš ï¸ MÃ¡ximo 10% |

---

## Siguiente Paso

Ver la [GuÃ­a de EvaluaciÃ³n](./EVALUACION.md) para interpretar estas mÃ©tricas.

---

## Referencias

- [Very Good Ventures - Road to 100% Coverage](https://www.verygood.ventures/blog/road-to-100-test-coverage)
- [Stack Overflow - What should NOT be unit tested](https://stackoverflow.com/questions/1084336/what-should-not-be-unit-tested)
- [100% Coverage is not trivial](https://blog.ploeh.dk/2025/11/10/100-coverage-is-not-that-trivial/)
